{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen2.5-Coder-7B (4-bit) â†’ HTML to JSX + Vue SFC Pipeline\n",
        "\n",
        "**Optimized for RTX 3070 Ti** with 4-bit quantization to fit VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07630bea",
      "metadata": {},
      "source": [
        "## 0) One-Time Setup\n",
        "\n",
        "### Python packages:\n",
        "```python\n",
        "!pip -q install -U transformers accelerate bitsandbytes pandas tqdm\n",
        "```\n",
        "\n",
        "### Node.js tools (run in terminal, not Jupyter):\n",
        "```powershell\n",
        "npm install @babel/parser @vue/compiler-sfc\n",
        "```\n",
        "\n",
        "**After installing Node tools, restart Jupyter so PATH updates.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5bcbe9",
      "metadata": {},
      "source": [
        "## 1) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "46a81be7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core imports successful\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import subprocess\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Core imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd8b662",
      "metadata": {},
      "source": [
        "## 2) Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ec6376f",
      "metadata": {},
      "source": [
        "## 2.1) Load & View Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e305c456",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'IN_CSV' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_raw = pd.read_csv(\u001b[43mIN_CSV\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_raw.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df_raw.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'IN_CSV' is not defined"
          ]
        }
      ],
      "source": [
        "df_raw = pd.read_csv(IN_CSV)\n",
        "\n",
        "print(f\"Shape: {df_raw.shape}\")\n",
        "print(f\"Columns: {list(df_raw.columns)}\\n\")\n",
        "\n",
        "# Show first 3 rows\n",
        "display(df_raw.head(3))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"\\nHTML (text) column:\")\n",
        "print(f\"  Non-empty: {df_raw['text'].notna().sum()}/{len(df_raw)}\")\n",
        "print(f\"  Avg length: {df_raw['text'].str.len().mean():.0f} chars\")\n",
        "print(f\"  Min length: {df_raw['text'].str.len().min():.0f} chars\")\n",
        "print(f\"  Max length: {df_raw['text'].str.len().max():.0f} chars\")\n",
        "\n",
        "print(f\"\\nSample HTML (row 0, first 500 chars):\")\n",
        "print(df_raw['text'].iloc[0][:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73c50cbc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input CSV : data/websight_50k/websight_50k.csv\n",
            "Output CSV: data/websight_50k/websight_50k_gen.csv\n",
            "HTML col  : text\n"
          ]
        }
      ],
      "source": [
        "IN_CSV   = \"data/websight_50k/websight_50k.csv\"\n",
        "OUT_CSV  = \"data/websight_50k/websight_50k_gen.csv\"\n",
        "HTML_COL = \"text\"\n",
        "\n",
        "PICSUM_HERO_W, PICSUM_HERO_H = 1600, 900\n",
        "PICSUM_LOGO_W, PICSUM_LOGO_H = 300, 300\n",
        "PICSUM_IMG_W,  PICSUM_IMG_H  = 900, 600\n",
        "\n",
        "print(f\"Input CSV : {IN_CSV}\")\n",
        "print(f\"Output CSV: {OUT_CSV}\")\n",
        "print(f\"HTML col  : {HTML_COL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c68ea8",
      "metadata": {},
      "source": [
        "## 3) Image Sanitization Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0c1e0d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanitization helpers defined\n"
          ]
        }
      ],
      "source": [
        "def picsum(seed: int, w: int, h: int) -> str:\n",
        "    return f\"https://picsum.photos/seed/{seed}/{w}/{h}\"\n",
        "\n",
        "\n",
        "def sanitize_html_assets(html: str, seed: int) -> str:\n",
        "    s = html\n",
        "    s = re.sub(\n",
        "        r\"background-image:\\s*url\\(['\\\"]?[^'\\\")]+['\\\"]?\\)\",\n",
        "        lambda m: f\"background-image: url('{picsum(seed, PICSUM_HERO_W, PICSUM_HERO_H)}')\",\n",
        "        s, flags=re.IGNORECASE,\n",
        "    )\n",
        "    s = re.sub(r\"https?://source\\.unsplash\\.com/[^\\s\\\"')]+\", picsum(seed, PICSUM_IMG_W, PICSUM_IMG_H), s)\n",
        "    s = re.sub(r\"https?://images\\.unsplash\\.com/[^\\s\\\"')]+\", picsum(seed, PICSUM_IMG_W, PICSUM_IMG_H), s)\n",
        "\n",
        "    def repl_img(tag):\n",
        "        full = tag.group(0)\n",
        "        lower = full.lower()\n",
        "        is_logo = \"logo\" in lower\n",
        "        w, h = (PICSUM_LOGO_W, PICSUM_LOGO_H) if is_logo else (PICSUM_IMG_W, PICSUM_IMG_H)\n",
        "        url = picsum(seed, w, h)\n",
        "        full = re.sub(r'src\\s*=\\s*[\"\\'][^\"\\']*[\"\\']', f'src=\"{url}\"', full, flags=re.IGNORECASE)\n",
        "        if re.search(r\"\\salt\\s*=\", full, flags=re.IGNORECASE) is None:\n",
        "            full = full[:-1] + ' alt=\"Image\">'\n",
        "        return full\n",
        "\n",
        "    s = re.sub(r\"<img\\b[^>]*\\bsrc\\s*=\\s*['\\\"][^'\\\"]*['\\\"][^>]*>\", repl_img, s, flags=re.IGNORECASE)\n",
        "    return s\n",
        "\n",
        "\n",
        "def enforce_picsum_in_code(code: str, seed: int) -> str:\n",
        "    s = code\n",
        "    s = re.sub(r\"https?://source\\.unsplash\\.com/[^\\s\\\"')]+\", picsum(seed, PICSUM_IMG_W, PICSUM_IMG_H), s)\n",
        "    s = re.sub(r\"https?://images\\.unsplash\\.com/[^\\s\\\"')]+\", picsum(seed, PICSUM_IMG_W, PICSUM_IMG_H), s)\n",
        "\n",
        "    def repl_src(m):\n",
        "        url = m.group(1)\n",
        "        if \"picsum.photos\" in url:\n",
        "            return m.group(0)\n",
        "        return f'src=\"{picsum(seed, PICSUM_IMG_W, PICSUM_IMG_H)}\"'\n",
        "\n",
        "    s = re.sub(r'src\\s*=\\s*\"([^\"]+)\"', repl_src, s)\n",
        "    s = re.sub(r\"src\\s*=\\s*'([^']+)'\", lambda m: repl_src(m).replace('\"', \"'\"), s)\n",
        "    return s\n",
        "\n",
        "print(\"Sanitization helpers defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a697ae",
      "metadata": {},
      "source": [
        "## 4) Node.js Validators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e705b36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validators defined\n"
          ]
        }
      ],
      "source": [
        "def validate_jsx(jsx_code: str) -> Tuple[bool, str]:\n",
        "    node_script = r\"\"\"\n",
        "const parser = require(\"@babel/parser\");\n",
        "let input = \"\";\n",
        "process.stdin.on(\"data\", c => input += c);\n",
        "process.stdin.on(\"end\", () => {\n",
        "  try {\n",
        "    parser.parse(input, {sourceType:\"module\", plugins:[\"jsx\",\"typescript\"]});\n",
        "    process.stdout.write(JSON.stringify({ok:true}));\n",
        "  } catch(e) {\n",
        "    process.stdout.write(JSON.stringify({ok:false, error:String(e.message||e)}));\n",
        "  }\n",
        "});\n",
        "\"\"\"\n",
        "    p = subprocess.run([\"node\",\"-e\",node_script], input=jsx_code.encode(\"utf-8\"),\n",
        "                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    out = p.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
        "    try:\n",
        "        j = json.loads(out)\n",
        "        return bool(j[\"ok\"]), j.get(\"error\", \"\")\n",
        "    except:\n",
        "        return False, f\"JSX validator error: {out[-200:] if out else p.stderr.decode('utf-8',errors='ignore')[-200:]}\"\n",
        "\n",
        "\n",
        "def validate_vue(vue_sfc: str) -> Tuple[bool, str]:\n",
        "    node_script = r\"\"\"\n",
        "const { parse } = require(\"@vue/compiler-sfc\");\n",
        "let input = \"\";\n",
        "process.stdin.on(\"data\", c => input += c);\n",
        "process.stdin.on(\"end\", () => {\n",
        "  try {\n",
        "    const res = parse(input, { filename: \"Component.vue\" });\n",
        "    const errs = res.errors || [];\n",
        "    if (errs.length) {\n",
        "      process.stdout.write(JSON.stringify({ok:false, error:String(errs[0])}));\n",
        "    } else {\n",
        "      process.stdout.write(JSON.stringify({ok:true}));\n",
        "    }\n",
        "  } catch(e) {\n",
        "    process.stdout.write(JSON.stringify({ok:false, error:String(e.message||e)}));\n",
        "  }\n",
        "});\n",
        "\"\"\"\n",
        "    p = subprocess.run([\"node\",\"-e\",node_script], input=vue_sfc.encode(\"utf-8\"),\n",
        "                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    out = p.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
        "    try:\n",
        "        j = json.loads(out)\n",
        "        return bool(j[\"ok\"]), j.get(\"error\", \"\")\n",
        "    except:\n",
        "        return False, f\"Vue validator error: {out[-200:] if out else p.stderr.decode('utf-8',errors='ignore')[-200:]}\"\n",
        "\n",
        "print(\"Validators defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b0a66e",
      "metadata": {},
      "source": [
        "## 5) Load Model (4-bit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea74a9c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Qwen/Qwen2.5-Coder-7B-Instruct in 4-bit...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ab9067ac555418181d8e8dd0a4c4113",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/339 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.49 GiB is allocated by PyTorch, and 37.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m bnb = BitsAndBytesConfig(\n\u001b[32m      8\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     bnb_4bit_use_double_quant=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     11\u001b[39m     bnb_4bit_compute_dtype=torch.float16,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel loaded on GPU (~8 GB VRAM)\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:374\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    373\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4063\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4046\u001b[39m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[32m   4047\u001b[39m load_config = LoadStateDictConfig(\n\u001b[32m   4048\u001b[39m     pretrained_model_name_or_path=pretrained_model_name_or_path,\n\u001b[32m   4049\u001b[39m     ignore_mismatched_sizes=ignore_mismatched_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4061\u001b[39m     download_kwargs=download_kwargs,\n\u001b[32m   4062\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m4063\u001b[39m loading_info, disk_offload_index = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4064\u001b[39m loading_info = \u001b[38;5;28mcls\u001b[39m._finalize_model_loading(model, load_config, loading_info)\n\u001b[32m   4065\u001b[39m model.eval()  \u001b[38;5;66;03m# Set model in evaluation mode to deactivate Dropout modules by default\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4182\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(model, state_dict, checkpoint_files, load_config)\u001b[39m\n\u001b[32m   4179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNeither a state dict nor checkpoint files were found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4182\u001b[39m loading_info, disk_offload_index = \u001b[43mconvert_and_load_state_dict_in_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtp_plan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tp_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4190\u001b[39m \u001b[38;5;66;03m# finally close all opened file pointers\u001b[39;00m\n\u001b[32m   4191\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m all_pointer:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:1192\u001b[39m, in \u001b[36mconvert_and_load_state_dict_in_model\u001b[39m\u001b[34m(model, state_dict, load_config, tp_plan, disk_offload_index)\u001b[39m\n\u001b[32m   1190\u001b[39m pbar.refresh()\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     realized_value = \u001b[43mmapping\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_param_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1199\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m target_name, param \u001b[38;5;129;01min\u001b[39;00m realized_value.items():\n\u001b[32m   1200\u001b[39m         param = param[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m param\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:665\u001b[39m, in \u001b[36mWeightRenaming.convert\u001b[39m\u001b[34m(self, layer_name, model, config, hf_quantizer, loading_info)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    656\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    657\u001b[39m     layer_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# Collect the tensors here - we use a new dictionary to avoid keeping them in memory in the internal\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# attribute during the whole process\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     collected_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmaterialize_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m     \u001b[38;5;66;03m# Perform renaming op (for a simple WeightRenaming, `self.source_patterns` and `self.target_patterns` can\u001b[39;00m\n\u001b[32m    668\u001b[39m     \u001b[38;5;66;03m# only be of length 1, and are actually the full key names - we also have only 1 single related tensor)\u001b[39;00m\n\u001b[32m    669\u001b[39m     target_key = \u001b[38;5;28mself\u001b[39m.target_patterns[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:641\u001b[39m, in \u001b[36mWeightTransform.materialize_tensors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# Async loading\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors[\u001b[32m0\u001b[39m], Future):\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     tensors = \u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[38;5;66;03m# Sync loading\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(tensors[\u001b[32m0\u001b[39m]):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:641\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# Async loading\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors[\u001b[32m0\u001b[39m], Future):\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     tensors = [future.result() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    642\u001b[39m \u001b[38;5;66;03m# Sync loading\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(tensors[\u001b[32m0\u001b[39m]):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:787\u001b[39m, in \u001b[36mspawn_materialize.<locals>._job\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_job\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_materialize_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Arnob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\core_model_loading.py:776\u001b[39m, in \u001b[36m_materialize_copy\u001b[39m\u001b[34m(tensor, device, dtype)\u001b[39m\n\u001b[32m    774\u001b[39m tensor = tensor[...]\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     tensor = \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.49 GiB is allocated by PyTorch, and 37.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Free previous model from GPU if re-running this cell\n",
        "if 'model' in dir():\n",
        "    del model\n",
        "if 'tokenizer' in dir():\n",
        "    del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(f\"GPU memory: {torch.cuda.mem_get_info()[0]/1024**3:.1f} GiB free / {torch.cuda.mem_get_info()[1]/1024**3:.1f} GiB total\")\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\n",
        "print(f\"Loading {MODEL_NAME} in 4-bit...\")\n",
        "\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb,\n",
        "    device_map=\"cuda:0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "print(f\"Model loaded on GPU (~8 GB VRAM)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec4f01bf",
      "metadata": {},
      "source": [
        "## 6) Prompts & Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421b7dab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompts and generation defined\n"
          ]
        }
      ],
      "source": [
        "def p_html_to_jsx(html: str) -> str:\n",
        "    return f\"\"\"You are a strict frontend compiler.\n",
        "Convert the given HTML into a single React component.\n",
        "\n",
        "Rules:\n",
        "- Output ONLY code.\n",
        "- Export a named component: GeneratedComponent\n",
        "- Preserve Tailwind classes.\n",
        "- Use className (not class).\n",
        "- Convert inline style strings to JSX objects.\n",
        "- Do NOT include <html>, <head>, <body>, or external <link> tags.\n",
        "- If there are <img> tags, keep the src URLs as provided (they are already Picsum).\n",
        "- Ensure valid JSX.\n",
        "\n",
        "HTML:\n",
        "```html\n",
        "{html}\n",
        "```\"\"\".strip()\n",
        "\n",
        "\n",
        "def p_html_to_vue(html: str) -> str:\n",
        "    return f\"\"\"You are a strict frontend compiler.\n",
        "Convert the given HTML into a Vue 3 Single File Component (SFC).\n",
        "\n",
        "Rules:\n",
        "- Output ONLY code.\n",
        "- Must be valid .vue SFC with <template> and <script setup>.\n",
        "- Preserve Tailwind classes.\n",
        "- Do NOT include <html>, <head>, <body>, or external <link> tags.\n",
        "- If there are <img> tags, keep the src URLs as provided (they are already Picsum).\n",
        "- Ensure valid Vue SFC.\n",
        "\n",
        "HTML:\n",
        "```html\n",
        "{html}\n",
        "```\"\"\".strip()\n",
        "\n",
        "\n",
        "def p_fix_jsx(bad: str, err: str) -> str:\n",
        "    return f\"\"\"Fix the following React JSX so it parses with Babel.\n",
        "\n",
        "Rules:\n",
        "- Output ONLY corrected code.\n",
        "- Keep component name GeneratedComponent.\n",
        "- Keep Tailwind classes.\n",
        "- No <html>/<head>/<body>/<link>.\n",
        "- Do not introduce Unsplash; keep Picsum if images exist.\n",
        "\n",
        "Babel error:\n",
        "{err}\n",
        "\n",
        "Code:\n",
        "{bad}\"\"\".strip()\n",
        "\n",
        "\n",
        "def p_fix_vue(bad: str, err: str) -> str:\n",
        "    return f\"\"\"Fix the following Vue SFC so it parses with @vue/compiler-sfc.\n",
        "\n",
        "Rules:\n",
        "- Output ONLY corrected code.\n",
        "- Must contain <template> and <script setup>.\n",
        "- No <html>/<head>/<body>/<link> in template.\n",
        "- Do not introduce Unsplash; keep Picsum if images exist.\n",
        "\n",
        "Compiler error:\n",
        "{err}\n",
        "\n",
        "Code:\n",
        "{bad}\"\"\".strip()\n",
        "\n",
        "\n",
        "def strip_code_fences(text: str) -> str:\n",
        "    \"\"\"Remove markdown code fences (```lang ... ```) from LLM output.\"\"\"\n",
        "    s = text.strip()\n",
        "    # Match ```lang\\n...\\n``` pattern\n",
        "    m = re.search(r'```(?:\\w+)?\\s*\\n(.*?)```', s, re.DOTALL)\n",
        "    if m:\n",
        "        return m.group(1).strip()\n",
        "    # Also handle if entire string starts with ``` and ends with ```\n",
        "    if s.startswith('```'):\n",
        "        s = re.sub(r'^```\\w*\\n?', '', s)\n",
        "        s = re.sub(r'\\n?```$', '', s)\n",
        "        return s.strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def llm_generate(prompt: str, max_new_tokens=600) -> str:\n",
        "    # Qwen2.5-Coder-Instruct needs chat template format\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.2,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    # Decode only the newly generated tokens (skip prompt)\n",
        "    new_tokens = out[0][inputs['input_ids'].shape[1]:]\n",
        "    txt = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "    return strip_code_fences(txt)\n",
        "\n",
        "print(\"Prompts and generation defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ca76cc",
      "metadata": {},
      "source": [
        "## 7) Pipeline Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43d69ef",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline function defined\n"
          ]
        }
      ],
      "source": [
        "def gen_validate(html: str, seed: int, repair_tries=2) -> Dict[str, str]:\n",
        "    html2 = sanitize_html_assets(html, seed)\n",
        "\n",
        "    # JSX\n",
        "    jsx = llm_generate(p_html_to_jsx(html2), max_new_tokens=650)\n",
        "    jsx = enforce_picsum_in_code(jsx, seed)\n",
        "    ok, err = validate_jsx(jsx)\n",
        "    t = 0\n",
        "    while (not ok) and t < repair_tries:\n",
        "        t += 1\n",
        "        jsx = llm_generate(p_fix_jsx(jsx, err), max_new_tokens=500)\n",
        "        jsx = enforce_picsum_in_code(jsx, seed)\n",
        "        ok, err = validate_jsx(jsx)\n",
        "    jsx_ok, jsx_err = ok, err\n",
        "\n",
        "    # Vue\n",
        "    vue = llm_generate(p_html_to_vue(html2), max_new_tokens=750)\n",
        "    vue = enforce_picsum_in_code(vue, seed)\n",
        "    ok, err = validate_vue(vue)\n",
        "    t = 0\n",
        "    while (not ok) and t < repair_tries:\n",
        "        t += 1\n",
        "        vue = llm_generate(p_fix_vue(vue, err), max_new_tokens=600)\n",
        "        vue = enforce_picsum_in_code(vue, seed)\n",
        "        ok, err = validate_vue(vue)\n",
        "    vue_ok, vue_err = ok, err\n",
        "\n",
        "    return {\n",
        "        \"html_sanitized\": html2,\n",
        "        \"jsx_code\": jsx,\n",
        "        \"vue_sfc\": vue,\n",
        "        \"jsx_valid\": jsx_ok,\n",
        "        \"vue_valid\": vue_ok,\n",
        "        \"jsx_error\": jsx_err,\n",
        "        \"vue_error\": vue_err,\n",
        "    }\n",
        "\n",
        "print(\"Pipeline function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454d17fb",
      "metadata": {},
      "source": [
        "## 8) Execute on CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154b7ef5",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcsv\u001b[39;00m\n\u001b[32m      3\u001b[39m SAMPLE_SIZE = \u001b[32m5\u001b[39m  \u001b[38;5;66;03m# how many to process this run (set to None for all)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m PROGRESS_FILE = \u001b[43mos\u001b[49m.path.join(os.path.dirname(OUT_CSV), \u001b[33m\"\u001b[39m\u001b[33mprogress.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# --- Load input data ---\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIN_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "SAMPLE_SIZE = 5  # how many to process this run (set to None for all)\n",
        "PROGRESS_FILE = os.path.join(os.path.dirname(OUT_CSV), \"progress.txt\")\n",
        "\n",
        "# --- Load input data ---\n",
        "print(f\"Loading CSV: {IN_CSV}\")\n",
        "df_full = pd.read_csv(IN_CSV)\n",
        "print(f\"Loaded {len(df_full)} rows, columns: {list(df_full.columns)}\")\n",
        "assert HTML_COL in df_full.columns\n",
        "\n",
        "# --- Read progress (which index to start from) ---\n",
        "start_idx = 0\n",
        "if os.path.exists(PROGRESS_FILE):\n",
        "    with open(PROGRESS_FILE, \"r\") as f:\n",
        "        start_idx = int(f.read().strip())\n",
        "    print(f\"Resuming from index {start_idx}\")\n",
        "else:\n",
        "    print(f\"Starting fresh from index 0\")\n",
        "\n",
        "# --- Determine end index ---\n",
        "end_idx = min(start_idx + SAMPLE_SIZE, len(df_full)) if SAMPLE_SIZE else len(df_full)\n",
        "todo = end_idx - start_idx\n",
        "print(f\"Will process rows {start_idx} to {end_idx - 1} ({todo} rows)\\n\")\n",
        "\n",
        "if todo <= 0:\n",
        "    print(\"Nothing to process.\")\n",
        "else:\n",
        "    # --- CSV output columns ---\n",
        "    OUT_COLS = [\n",
        "        \"id\", \"image_path\", \"text\", \"llm_generated_idea\",\n",
        "        \"jsx_code\", \"vue_sfc\", \"jsx_valid\", \"vue_valid\", \"jsx_error\", \"vue_error\",\n",
        "    ]\n",
        "\n",
        "    # --- Open output CSV (append if resuming, write header if new) ---\n",
        "    os.makedirs(os.path.dirname(OUT_CSV) or \".\", exist_ok=True)\n",
        "    write_header = (start_idx == 0) or not os.path.exists(OUT_CSV)\n",
        "    f_out = open(OUT_CSV, \"a\" if not write_header else \"w\", newline=\"\", encoding=\"utf-8\")\n",
        "    writer = csv.DictWriter(f_out, fieldnames=OUT_COLS)\n",
        "    if write_header:\n",
        "        writer.writeheader()\n",
        "\n",
        "    jsx_valid_count = 0\n",
        "    vue_valid_count = 0\n",
        "\n",
        "    for idx in tqdm(range(start_idx, end_idx), desc=\"Generating\"):\n",
        "        row = df_full.iloc[idx]\n",
        "        html = \"\" if pd.isna(row[HTML_COL]) else str(row[HTML_COL])\n",
        "        seed = int(row[\"id\"]) if (\"id\" in df_full.columns and pd.notna(row[\"id\"])) else idx\n",
        "\n",
        "        r = gen_validate(html, seed, repair_tries=2)\n",
        "\n",
        "        # Build output row\n",
        "        out_row = {}\n",
        "        for c in OUT_COLS:\n",
        "            if c in r:\n",
        "                out_row[c] = r[c]\n",
        "            elif c in row.index:\n",
        "                out_row[c] = \"\" if pd.isna(row[c]) else row[c]\n",
        "            else:\n",
        "                out_row[c] = \"\"\n",
        "\n",
        "        # Write row immediately\n",
        "        writer.writerow(out_row)\n",
        "        f_out.flush()\n",
        "\n",
        "        # Update progress file\n",
        "        with open(PROGRESS_FILE, \"w\") as pf:\n",
        "            pf.write(str(idx + 1))\n",
        "\n",
        "        if r[\"jsx_valid\"]:\n",
        "            jsx_valid_count += 1\n",
        "        if r[\"vue_valid\"]:\n",
        "            vue_valid_count += 1\n",
        "\n",
        "    f_out.close()\n",
        "\n",
        "    print(f\"\\nDone! Processed rows {start_idx}-{end_idx - 1}\")\n",
        "    print(f\"Output: {OUT_CSV}\")\n",
        "    print(f\"Progress: {PROGRESS_FILE} (next start = {end_idx})\")\n",
        "    print(f\"JSX valid: {jsx_valid_count}/{todo} ({jsx_valid_count/todo:.1%})\")\n",
        "    print(f\"Vue valid: {vue_valid_count}/{todo} ({vue_valid_count/todo:.1%})\")\n",
        "\n",
        "# Load result for downstream cells\n",
        "out_df = pd.read_csv(OUT_CSV, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e0bd6c",
      "metadata": {},
      "source": [
        "## 9) Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde31ea7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== VALIDATION SUMMARY ===\n",
            "Rows: 5\n",
            "JSX valid: 5/5 (100.0%)\n",
            "Vue valid: 0/5 (0.0%)\n",
            "\n",
            "--- Row 0 ---\n",
            "JSX valid=True, first 200 chars:\n",
            "\n",
            "\n",
            "Vue valid=False, first 200 chars:\n",
            "\n",
            "\n",
            "Vue errors (5 rows):\n",
            "  [0] SyntaxError: At least one <template> or <script> is required in a single file component. Component.v\n",
            "  [1] SyntaxError: At least one <template> or <script> is required in a single file component. Component.v\n",
            "  [2] SyntaxError: At least one <template> or <script> is required in a single file component. Component.v\n"
          ]
        }
      ],
      "source": [
        "print(\"=== VALIDATION SUMMARY ===\")\n",
        "print(f\"Rows: {len(out_df)}\")\n",
        "print(f\"JSX valid: {out_df['jsx_valid'].sum()}/{len(out_df)} ({out_df['jsx_valid'].mean():.1%})\")\n",
        "print(f\"Vue valid: {out_df['vue_valid'].sum()}/{len(out_df)} ({out_df['vue_valid'].mean():.1%})\")\n",
        "\n",
        "if len(out_df) > 0:\n",
        "    s = out_df.iloc[0]\n",
        "    print(f\"\\n--- Row 0 ---\")\n",
        "    print(f\"JSX valid={s['jsx_valid']}, first 200 chars:\")\n",
        "    print(str(s['jsx_code'])[:200])\n",
        "    print(f\"\\nVue valid={s['vue_valid']}, first 200 chars:\")\n",
        "    print(str(s['vue_sfc'])[:200])\n",
        "\n",
        "jsx_errs = out_df[out_df[\"jsx_error\"].notna() & (out_df[\"jsx_error\"] != \"\")]\n",
        "vue_errs = out_df[out_df[\"vue_error\"].notna() & (out_df[\"vue_error\"] != \"\")]\n",
        "if len(jsx_errs) > 0:\n",
        "    print(f\"\\nJSX errors ({len(jsx_errs)} rows):\")\n",
        "    for idx, row in jsx_errs.head(3).iterrows():\n",
        "        print(f\"  [{idx}] {str(row['jsx_error'])[:100]}\")\n",
        "if len(vue_errs) > 0:\n",
        "    print(f\"\\nVue errors ({len(vue_errs)} rows):\")\n",
        "    for idx, row in vue_errs.head(3).iterrows():\n",
        "        print(f\"  [{idx}] {str(row['vue_error'])[:100]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b7bcdf",
      "metadata": {},
      "source": [
        "## 10) Save Merged Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0af4dc7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 5 rows to: data/websight_100_stream/websight_100_merged.csv\n",
            "Columns: ['id', 'image_path', 'text', 'llm_generated_idea', 'jsx_code', 'vue_sfc', 'jsx_valid', 'vue_valid', 'jsx_error', 'vue_error']\n",
            "Size: 12.2 KB\n",
            "JSX non-empty: 0/5\n",
            "Vue non-empty: 0/5\n"
          ]
        }
      ],
      "source": [
        "MERGED_CSV = \"data/websight_50k/websight_50k_merged.csv\"\n",
        "\n",
        "KEEP_COLS = [\n",
        "    \"id\", \"image_path\", \"text\", \"llm_generated_idea\",\n",
        "    \"jsx_code\", \"vue_sfc\", \"jsx_valid\", \"vue_valid\", \"jsx_error\", \"vue_error\",\n",
        "]\n",
        "cols = [c for c in KEEP_COLS if c in out_df.columns]\n",
        "merged_df = out_df[cols].copy()\n",
        "\n",
        "os.makedirs(os.path.dirname(MERGED_CSV) or \".\", exist_ok=True)\n",
        "merged_df.to_csv(MERGED_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Saved {len(merged_df)} rows to: {MERGED_CSV}\")\n",
        "print(f\"Columns: {list(merged_df.columns)}\")\n",
        "print(f\"Size: {os.path.getsize(MERGED_CSV) / 1024:.1f} KB\")\n",
        "print(f\"JSX non-empty: {(merged_df['jsx_code'].str.len() > 10).sum()}/{len(merged_df)}\")\n",
        "print(f\"Vue non-empty: {(merged_df['vue_sfc'].str.len() > 10).sum()}/{len(merged_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d48d5f2d",
      "metadata": {},
      "source": [
        "## 11) Check 5 Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9898ddca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5 rows\n",
            "\n",
            "================================================================================\n",
            "  SAMPLE 1/5\n",
            "================================================================================\n",
            "\n",
            "[id]         0\n",
            "[image_path] data/websight_100_stream\\images\\00000.png\n",
            "\n",
            "[llm_generated_idea]\n",
            "Fashion Brand: A visually stunning layout with a full-width, rotating image carousel showcasing their latest collections, a bold, center-aligned logo, and a bottom navigation menu. The color palette is inspired by the latest fashion trends.\n",
            "\n",
            "[Original HTML] (1274 chars)\n",
            "<html>\n",
            "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
            "<body class=\"bg-gray-100\">\n",
            "  <div class=\"flex flex-col items-center justify-center h-screen\">\n",
            "    <h1 class=\"text-4xl font-bold text-center text-gray-800\">Fashion Brand</h1>\n",
            "    <p class=\"mt-4 text-lg text-center text-gray-600\">\n",
            "      Fashion Brand is a leading fashion brand that offers a wi...\n",
            "\n",
            "[JSX] valid=True  (0 chars)\n",
            "\n",
            "\n",
            "[Vue SFC] valid=False  (0 chars)\n",
            "\n",
            "  Error: SyntaxError: At least one <template> or <script> is required in a single file component. Component.vue\n",
            "\n",
            "================================================================================\n",
            "  SAMPLE 2/5\n",
            "================================================================================\n",
            "\n",
            "[id]         1\n",
            "[image_path] data/websight_100_stream\\images\\00001.png\n",
            "\n",
            "[llm_generated_idea]\n",
            "Restaurant Chain: A design with a mouth-watering header image of a popular dish, a top navigation menu with pages for location, menu, and order online. The footer displays social media icons, a newsletter sign-up form, and contact information.\n",
            "\n",
            "[Original HTML] (2135 chars)\n",
            "<html>\n",
            "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
            "<body class=\"bg-gray-100 font-sans leading-normal tracking-normal\">\n",
            "    <nav class=\"flex items-center justify-between flex-wrap bg-teal-500 p-6\">\n",
            "        <div class=\"flex items-center flex-shrink-0 text-white mr-6\">\n",
            "            <span class=\"font-semibold text-xl tracking-tight\">Restaurant Ch...\n",
            "\n",
            "[JSX] valid=True  (0 chars)\n",
            "\n",
            "\n",
            "[Vue SFC] valid=False  (0 chars)\n",
            "\n",
            "  Error: SyntaxError: At least one <template> or <script> is required in a single file component. Component.vue\n",
            "\n",
            "================================================================================\n",
            "  SAMPLE 3/5\n",
            "================================================================================\n",
            "\n",
            "[id]         2\n",
            "[image_path] data/websight_100_stream\\images\\00002.png\n",
            "\n",
            "[llm_generated_idea]\n",
            "Consulting Firm: A clean, professional design with a full-width image and a tagline, a left column for the main navigation menu, and a right column for featuring key staff members and their service offerings. A muted color palette evokes trust and expertise.\n",
            "\n",
            "[Original HTML] (2253 chars)\n",
            "<html>\n",
            "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
            "<body class=\"bg-gray-100 font-sans leading-normal tracking-normal\">\n",
            "    <nav class=\"flex items-center justify-between flex-wrap bg-teal-500 p-6\">\n",
            "        <div class=\"flex items-center flex-shrink-0 text-white mr-6\">\n",
            "            <span class=\"font-semibold text-xl tracking-tight\">Consulting Fi...\n",
            "\n",
            "[JSX] valid=True  (0 chars)\n",
            "\n",
            "\n",
            "[Vue SFC] valid=False  (0 chars)\n",
            "\n",
            "  Error: SyntaxError: At least one <template> or <script> is required in a single file component. Component.vue\n",
            "\n",
            "================================================================================\n",
            "  SAMPLE 4/5\n",
            "================================================================================\n",
            "\n",
            "[id]         3\n",
            "[image_path] data/websight_100_stream\\images\\00003.png\n",
            "\n",
            "[llm_generated_idea]\n",
            "Real Estate Agency: A user-friendly design with a header featuring a property image and search functionality, a top navigation menu with links to the various property listings. The page includes a grid layout for listing images, and a footer with contact information and social media icons.\n",
            "\n",
            "[Original HTML] (2624 chars)\n",
            "<html>\n",
            "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
            "<body class=\"bg-gray-100 font-sans leading-normal tracking-normal\">\n",
            "    <header class=\"bg-white text-gray-800\">\n",
            "        <div class=\"container mx-auto flex flex-wrap p-5 flex-col md:flex-row items-center\">\n",
            "            <a class=\"flex title-font font-medium items-center text-gray-900 mb-4 md:mb...\n",
            "\n",
            "[JSX] valid=True  (0 chars)\n",
            "\n",
            "\n",
            "[Vue SFC] valid=False  (0 chars)\n",
            "\n",
            "  Error: SyntaxError: At least one <template> or <script> is required in a single file component. Component.vue\n",
            "\n",
            "================================================================================\n",
            "  SAMPLE 5/5\n",
            "================================================================================\n",
            "\n",
            "[id]         4\n",
            "[image_path] data/websight_100_stream\\images\\00004.png\n",
            "\n",
            "[llm_generated_idea]\n",
            "Education Platform: A design with a wide, hero image, a centered logo, and a top navigation menu featuring links for courses, pricing, and about the company. The site includes a feature section where students can share testimonials and success stories. A warm, approachable color palette is used to i...\n",
            "\n",
            "[Original HTML] (1684 chars)\n",
            "<html>\n",
            "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
            "<body class=\"bg-gray-100 font-sans leading-normal tracking-normal\">\n",
            "    <header class=\"bg-cover bg-center h-screen\" style=\"background-image: url('https://source.unsplash.com/random/1600x900/?education')\">\n",
            "        <div class=\"container mx-auto px-6 md:px-12 relative z-10 flex items-center h-f...\n",
            "\n",
            "[JSX] valid=True  (0 chars)\n",
            "\n",
            "\n",
            "[Vue SFC] valid=False  (0 chars)\n",
            "\n",
            "  Error: SyntaxError: At least one <template> or <script> is required in a single file component. Component.vue\n",
            "\n",
            "================================================================================\n",
            "Done - reviewed 5 samples\n"
          ]
        }
      ],
      "source": [
        "df_check = pd.read_csv(MERGED_CSV, encoding=\"utf-8\")\n",
        "print(f\"Loaded {len(df_check)} rows\\n\")\n",
        "\n",
        "NUM = 5\n",
        "samples = df_check.head(NUM)\n",
        "\n",
        "def safe(val):\n",
        "    return str(val) if pd.notna(val) else \"\"\n",
        "\n",
        "for i, (_, row) in enumerate(samples.iterrows()):\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"  SAMPLE {i+1}/{NUM}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(f\"\\n[id]         {row.get('id', 'N/A')}\")\n",
        "    print(f\"[image_path] {safe(row.get('image_path'))}\")\n",
        "\n",
        "    idea = safe(row.get(\"llm_generated_idea\"))\n",
        "    print(f\"\\n[llm_generated_idea]\")\n",
        "    print(idea[:300] + (\"...\" if len(idea) > 300 else \"\"))\n",
        "\n",
        "    html = safe(row.get(\"text\"))\n",
        "    print(f\"\\n[Original HTML] ({len(html)} chars)\")\n",
        "    print(html[:400] + (\"...\" if len(html) > 400 else \"\"))\n",
        "\n",
        "    jsx = safe(row.get(\"jsx_code\"))\n",
        "    print(f\"\\n[JSX] valid={row.get('jsx_valid', False)}  ({len(jsx)} chars)\")\n",
        "    print(jsx[:500] + (\"...\" if len(jsx) > 500 else \"\"))\n",
        "    jsx_e = safe(row.get(\"jsx_error\"))\n",
        "    if jsx_e:\n",
        "        print(f\"  Error: {jsx_e[:150]}\")\n",
        "\n",
        "    vue = safe(row.get(\"vue_sfc\"))\n",
        "    print(f\"\\n[Vue SFC] valid={row.get('vue_valid', False)}  ({len(vue)} chars)\")\n",
        "    print(vue[:500] + (\"...\" if len(vue) > 500 else \"\"))\n",
        "    vue_e = safe(row.get(\"vue_error\"))\n",
        "    if vue_e:\n",
        "        print(f\"  Error: {vue_e[:150]}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"Done - reviewed {NUM} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21beb467",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- **3070 Ti + 4-bit**: ~8GB VRAM, zero crashes\n",
        "- **Token limits**: JSX=650, Vue=750, repairs=500-600\n",
        "- **Validation**: Parse-level (Babel / Vue compiler-sfc)\n",
        "- **Auto-repair**: Up to 2 retries per output\n",
        "- **Images**: All external URLs replaced with deterministic Picsum\n",
        "\n",
        "### Next Steps\n",
        "- Upgrade to actual build validation (React + Vue)\n",
        "- Scale to larger samples (500+)\n",
        "- Fine-tune prompts if validation rates are low"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
